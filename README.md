# Bulk OCR Processor

A powerful Node.js application that processes JPG/PNG images in bulk using Google Lens OCR technology. Perfect for extracting text from images containing multiple languages including Hindi, Gujarati, Sanskrit, and other Indian languages.

## âœ¨ Features

- ğŸ” **Bulk Processing**: Process hundreds of images automatically
- ğŸ“ **Folder Structure Preservation**: Maintains exact folder hierarchy in output
- ğŸŒ **Multi-Language Support**: Supports 100+ languages including Hindi, Gujarati, Sanskrit
- ğŸš€ **Optimized Speed**: 3-5x faster processing with intelligent rate management
- ğŸ§  **Dynamic Rate Adjustment**: Automatically optimizes processing speed based on performance
- âš¡ **Concurrent Processing**: Processes multiple files simultaneously while respecting rate limits
- ğŸ“Š **Progress Tracking**: Real-time progress bars and detailed reports
- ğŸ”„ **Smart Error Recovery**: Automatic retry mechanism with exponential backoff
- ğŸ“ **Smart Text Assembly**: Preserves paragraph structure and text flow
- ğŸ¯ **Clean Output**: Text-only files without metadata headers

## ğŸ“‹ Requirements

- **Node.js**: Version 14 or higher ([Download Node.js](https://nodejs.org/))
- **Internet Connection**: Required for Google Lens API access
- **Operating System**: Windows, macOS, or Linux

## ğŸš€ Quick Start

### 1. Download & Setup

**For Windows Users:**
```powershell
# Clone or download this repository
git clone https://github.com/vharsh43/Google-Lens-OCR
cd Google-Lens-OCR

# Install dependencies (Windows-specific fix)
npm install --include=optional sharp
npm install
```

**For macOS/Linux Users:**
```bash
# Clone or download this repository
git clone https://github.com/vharsh43/Google-Lens-OCR
cd Google-Lens-OCR

# Install dependencies
npm install
```

### 2. Add Your Images
Place your JPG/JPEG/PNG files in the `JPG2TXT` folder with any structure you want:
```
JPG2TXT/
â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ hindi-document.jpg
â”‚   â””â”€â”€ gujarati-text.jpg
â”œâ”€â”€ books/
â”‚   â”œâ”€â”€ chapter1/
â”‚   â”‚   â””â”€â”€ page001.jpg
â”‚   â””â”€â”€ chapter2/
â”‚       â””â”€â”€ page001.jpg
â””â”€â”€ receipts/
    â””â”€â”€ receipt1.jpg
```

### 3. Run OCR Processing
```bash
# Process all images
npm start

# Test with first 3 files only
npm run test
```

### 4. Get Results
Find extracted text in `TXT_Files/` with the same folder structure:
```
TXT_Files/
â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ hindi-document.txt
â”‚   â””â”€â”€ gujarati-text.txt
â”œâ”€â”€ books/
â”‚   â”œâ”€â”€ chapter1/
â”‚   â”‚   â””â”€â”€ page001.txt
â”‚   â””â”€â”€ chapter2/
â”‚       â””â”€â”€ page001.txt
â””â”€â”€ receipts/
    â””â”€â”€ receipt1.txt
```

## ğŸ“– Detailed Usage

### Available Commands

| Command | Description |
|---------|-------------|
| `npm start` | Process all images in JPG2TXT folder |
| `npm run test` | Test mode - process only first 3 files |
| `npm run process` | Alternative command for processing |

### Supported File Types
- `.jpg` and `.jpeg` files
- `.png` files
- Any folder depth (unlimited nesting supported)

### Output Format
- **Clean text files**: Only extracted text, no metadata
- **Preserved formatting**: Maintains paragraph structure
- **Same folder structure**: Exact replica of input organization
- **UTF-8 encoding**: Supports all international characters

## âš™ï¸ Configuration

### ğŸ§  Intelligent Processing (Default - Recommended)

The system automatically optimizes processing speed:
- **Starts with**: 10 files per batch, 3-second delays
- **Scales up**: When success rate > 95% (faster processing)
- **Scales down**: When success rate < 80% (more reliable)
- **Learns**: Finds optimal settings for your system and internet speed

### ğŸ”§ Manual Configuration

You can customize the behavior by editing `src/config.js`:

```javascript
export const config = {
  processing: {
    // Base settings (automatically optimized)
    batchSize: 10,             // Files per batch (dynamic)
    batchDelay: 3000,          // Delay between batches (dynamic)
    maxConcurrency: 3,         // Simultaneous file processing
    
    // Dynamic rate adjustment
    dynamicRateAdjustment: {
      enabled: true,           // Enable intelligent optimization
      maxBatchSize: 20,        // Maximum batch size allowed
      minBatchSize: 3,         // Minimum batch size allowed
      scaleUpThreshold: 0.95,  // Scale up when 95%+ success
      scaleDownThreshold: 0.80 // Scale down when <80% success
    },
    
    // Error handling
    maxRetries: 3,             // Retry failed files 3 times
    timeout: 45000             // 45 second timeout per file
  },
  
  output: {
    includeMetadata: false,    // Clean text only (no headers)
    encoding: 'utf8'           // Support all languages
  }
};
```

### ğŸ“ˆ Performance Modes

**Default Mode (Recommended)**:
```bash
npm start  # Automatic optimization enabled
```

**Conservative Mode**: Disable auto-optimization in config.js
```javascript
dynamicRateAdjustment: { enabled: false }
```

## ğŸŒ Language Support

**Confirmed Working Languages:**
- **Hindi** (à¤¹à¤¿à¤‚à¤¦à¥€)
- **Gujarati** (àª—à«àªœàª°àª¾àª¤à«€) 
- **Sanskrit** (à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤)
- **English**
- **Many others** (100+ languages supported by Google Lens)

**Auto-Detection**: The system automatically detects the language in each image.

## ğŸ“Š Sample Output

**Input Image**: `document.jpg` containing Gujarati text

**Output**: `TXT_Files/document.txt`
```
àª…. à«§]
àª¶à«àª°à«€àª®àª¦à«àª­àª¾àª—àªµàª¤-àª®àª¾àª¹àª¾àª¤à«àª®à«àª¯ 3
àª®à«‡àª¨àª¿àª°à«‡ àª­àª—àªµàª¦à«àª°à«‚àªªàª‚ àª¶àª¾àª¸à«àª¤à«àª° àª­àª¾àª—àªµàª¤àª‚ àª•àª²à«€ !
àªªàª àª¨àª¾àªšà«àª›àªµàª£àª¾àª¤à«àª¸àª˜à«‹ àªµà«ˆàª•à«àª£à«àª¡àª«àª²àª¦àª¾àª¯àª•àª®à« à¥¥ à«¨à«¦l àª¸àªªà«àª¤àª¾àª¹à«‡àª¨ àª¶à«àª°à«àª¤àª¿àª‚ àªšàª¿àª¤àª¤à«àª¸àª°à«àªµàª¥àª¾ àª®à«àª•à«àª¤àª¿àª¦àª¾àª¯àª•àª®à«
àª¸àª¨àª•àª¾àªƒ àªªà«àª°àª¾ àªªà«àª°à«‹àª•à«àª¤ àª¨àª¾àª°àª¦àª¾àª¯ àª¦àª¯àª¾àªªàª°à«ˆàªƒ à¥¥ à«¨à«§à¥¥
```

*Notice how the text flows naturally, preserving paragraph structure.*

## ğŸ§  How Dynamic Optimization Works

The system includes an intelligent rate adjustment feature that maximizes processing speed while avoiding rate limits:

### ğŸ“Š Monitoring Phase
- **Tracks success rate** for every batch of files processed
- **Measures performance** over rolling windows (last 3 batches)
- **Detects rate limiting** automatically from API responses

### âš¡ Scaling Up (Better Performance)
When success rate > 95%:
- **Increases batch size** (more files per batch)
- **Reduces delays** (faster processing)
- **Maintains safety limits** (max 20 files per batch)

### ğŸ›¡ï¸ Scaling Down (Better Reliability)  
When success rate < 80%:
- **Decreases batch size** (fewer files per batch)
- **Increases delays** (more conservative timing)
- **Prevents failures** from rate limiting

### ğŸ¯ Console Output
Watch for these messages:
```bash
ğŸ§  Dynamic rate adjustment enabled - will optimize processing speed automatically
ğŸ”„ Dynamic adjustment 1: Scaling UP (high success rate)
   Batch size: 10 â†’ 15
   Batch delay: 3000ms â†’ 2000ms
   Recent success rate: 98%
```

## ğŸ”§ Troubleshooting

### âŒ "No files found to process"
**Solution**: 
- Place JPG/JPEG/PNG files in the `JPG2TXT` folder
- Check file extensions are supported (`.jpg`, `.jpeg`, `.png`)
- Ensure files aren't in hidden folders

### âŒ OCR Processing Fails
**Solution**:
- **Check internet connection** (Google Lens API requires internet)
- **Verify image quality** (blurry images may fail)
- **Check file size** (very large files may timeout)
- **Review error log**: Check `failed-files.log` for details

### âŒ Permission Errors
**Solution**:
- Run terminal/command prompt as administrator
- Check folder permissions for `TXT_Files` directory
- Ensure Node.js has write access to the project folder

### âŒ "npm install" fails
**Solution**:
- Update Node.js to version 14 or higher
- Clear npm cache: `npm cache clean --force`
- Delete `node_modules` and `package-lock.json`, then retry `npm install`

### âŒ Windows: "Could not load the sharp module" Error
**Solution**:
```powershell
# Try these commands in order:
npm install --include=optional sharp
npm install --os=win32 --cpu=x64 sharp

# If still failing, clean reinstall:
Remove-Item -Recurse -Force node_modules
Remove-Item package-lock.json
npm install
```

**Alternative for Windows:**
- Install Visual Studio Build Tools
- Run PowerShell as Administrator
- Use `npm install --global windows-build-tools`

## ğŸ–¥ï¸ System Requirements

| Component | Requirement |
|-----------|-------------|
| **Node.js** | Version 14.0+ |
| **RAM** | 512MB minimum |
| **Storage** | 100MB for program + space for output files |
| **Internet** | Required (Google Lens API) |
| **OS** | Windows 10+, macOS 10.14+, Ubuntu 18.04+ |

## ğŸ“‹ Processing Statistics

After processing, you'll see a comprehensive summary:
```
ğŸ“Š Processing Summary
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total Files: 50
Successful: 49
Failed: 1
Success Rate: 98%
Total Duration: 125.7s
Avg Time/File: 2.5s

ğŸ§  Dynamic Rate Adjustment Stats:
Adjustments Made: 3
Final Batch Size: 15
Final Batch Delay: 2.0s
Throughput Improvement: +240% (estimated)

Output directory: /path/to/TXT_Files
```

### ğŸš€ Performance Improvements

**Before Optimization**: ~12 files/minute
**After Optimization**: ~75 files/minute (theoretical maximum)
**Typical Real-World**: 25-40 files/minute depending on:
- Image complexity
- Internet speed  
- System performance
- API response times

## ğŸ¯ Best Practices

### ğŸ“¸ Image Quality
1. **Clear Images**: Use high-contrast, well-lit images for best results
2. **Resolution**: 300+ DPI recommended, but system handles various sizes
3. **File Size**: Large files (>10MB) may process slower but are supported

### ğŸš€ Performance Optimization
4. **Let It Learn**: Allow the system to run for 15-20 files to optimize settings
5. **Monitor Output**: Watch for dynamic adjustment messages in console
6. **Internet Speed**: Stable internet improves processing consistency

### ğŸ“ Organization & Workflow  
7. **Folder Structure**: Organize files logically before processing - output mirrors input
8. **Backup Originals**: Keep source images safe as processing is one-way
9. **Batch Processing**: System automatically handles large batches (100+ files)
10. **Review Results**: Verify text accuracy, especially for handwritten content

### âš¡ Troubleshooting Performance
- **Slow processing**: Check internet connection and let dynamic adjustment optimize
- **High failure rate**: System will automatically slow down and become more reliable
- **Inconsistent speed**: Normal - system adapts to current conditions

## ğŸ¤ Contributing & Support

- **Issues**: Report bugs or request features
- **Code**: Fork and submit pull requests
- **Documentation**: Help improve this README

## ğŸ“„ License

MIT License - Use freely for personal and commercial projects.

---

**Made with â¤ï¸ for multilingual OCR processing**